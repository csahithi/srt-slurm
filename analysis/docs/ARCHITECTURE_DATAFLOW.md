# SRT-SLURM Log Analysis Architecture - Dataflow Diagram

## Overview
This document describes the data flow through the log analysis system, from raw log files to structured data models.

---

## 1. Entry Point: RunLoader

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           RunLoader                                  â”‚
â”‚  Entry point for loading and analyzing benchmark run data           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â”œâ”€â”€â–º discover_runs()
                                    â”œâ”€â”€â–º load_single(job_id)
                                    â””â”€â”€â–º load_node_metrics_for_run()
                                    
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                               â”‚
                    â–¼                               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Metadata Discovery â”‚         â”‚  Results Parsing   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Metadata Discovery Flow

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    Source Files (per run)       â”‚
                        â”‚                                 â”‚
                        â”‚  ğŸ“ {job_id}/metadata.json      â”‚
                        â”‚  ğŸ“ {job_id}/config.yaml        â”‚
                        â”‚  ğŸ“ {job_id}/*.json             â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â”‚ read by
                                      â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   RunLoader._load_metadata()    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â”‚ creates
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            RunMetadata                                     â”‚
â”‚  Fields:                                   Source File:                    â”‚
â”‚  â€¢ job_id                                  ğŸ“ metadata.json                â”‚
â”‚  â€¢ job_name                                ğŸ“ metadata.json                â”‚
â”‚  â€¢ run_date                                ğŸ“ metadata.json                â”‚
â”‚  â€¢ mode (monolithic/disaggregated)         ğŸ“ metadata.json                â”‚
â”‚  â€¢ prefill_nodes, decode_nodes             ğŸ“ metadata.json                â”‚
â”‚  â€¢ prefill_workers, decode_workers         ğŸ“ metadata.json                â”‚
â”‚  â€¢ model: ModelConfig                      ğŸ“ metadata.json                â”‚
â”‚    - path, tensor_parallel, ...                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Profiler/Benchmark Results Flow

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚        Profiler Type Detection          â”‚
                        â”‚                                         â”‚
                        â”‚  ğŸ“ logs/benchmark.out                  â”‚
                        â”‚    - Search for "SA-Bench Config"       â”‚
                        â”‚    - Search for "aiperf" commands       â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â”‚ determines
                                         â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚       ProfilerMetadata                  â”‚
                        â”‚  Fields:              Source:           â”‚
                        â”‚  â€¢ profiler_type      benchmark.out     â”‚
                        â”‚  â€¢ isl                benchmark.out     â”‚
                        â”‚  â€¢ osl                benchmark.out     â”‚
                        â”‚  â€¢ concurrencies      benchmark.out     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â”‚ used to find
                                         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              BenchmarkParser.find_result_directory()           â”‚
        â”‚                                                                â”‚
        â”‚  SA-Bench:                    Mooncake-Router:                â”‚
        â”‚  ğŸ“ sa-bench_isl_*_osl_*/     ğŸ“ logs/artifacts/*/            â”‚
        â”‚     result_*.json (PRIMARY)      profile_export_aiperf.json   â”‚
        â”‚     benchmark.out (FALLBACK)     (PRIMARY)                    â”‚
        â”‚                               ğŸ“ logs/benchmark.out           â”‚
        â”‚                                  (FALLBACK)                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â”‚ parse_result_directory()
                                         â”‚ âš ï¸ JSON files are PRIMARY source of truth
                                         â”‚    .out files are FALLBACK only
                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          ProfilerResults                                  â”‚
â”‚  Fields:                               Source Files (Priority Order):     â”‚
â”‚  â€¢ output_tps: list[float]             1ï¸âƒ£ ğŸ“ result_*.json (SA-Bench)    â”‚
â”‚  â€¢ request_throughput: list[float]        ğŸ“ profile_export_aiperf.json   â”‚
â”‚  â€¢ concurrency_values: list[int]             (Mooncake-Router)            â”‚
â”‚  â€¢ mean_ttft_ms: list[float]           2ï¸âƒ£ ğŸ“ logs/benchmark.out (fallback)â”‚
â”‚  â€¢ mean_itl_ms: list[float]                                               â”‚
â”‚  â€¢ mean_e2el_ms: list[float]            One entry per concurrency level   â”‚
â”‚  â€¢ p99_ttft_ms, median_ttft_ms, ...                                       â”‚
â”‚  â€¢ total_input_tokens: list[int]        JSON = Source of Truth âœ¨         â”‚
â”‚  â€¢ total_output_tokens: list[int]       .out = Fallback only âš ï¸           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Benchmark Launch Command Flow

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    Source File                  â”‚
                        â”‚  ğŸ“ logs/benchmark.out          â”‚
                        â”‚    - Command line arguments     â”‚
                        â”‚    - SA-Bench Config: header    â”‚
                        â”‚    - aiperf profile commands    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â”‚ parse_launch_command()
                                      â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   BenchmarkParser               â”‚
                        â”‚   (SA-Bench or Mooncake)        â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â”‚ creates
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      BenchmarkLaunchCommand                                â”‚
â”‚  Fields:                                   Source:                         â”‚
â”‚  â€¢ benchmark_type                          ğŸ“ logs/benchmark.out           â”‚
â”‚  â€¢ raw_command                             ğŸ“ logs/benchmark.out           â”‚
â”‚  â€¢ extra_args: dict                        ğŸ“ logs/benchmark.out           â”‚
â”‚    - base_url, model, input_len,                                           â”‚
â”‚      output_len, max_concurrency, ...                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. Node Metrics Flow

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚          Source Files (per node/worker)         â”‚
                        â”‚                                                 â”‚
                        â”‚  ğŸ“ logs/{node}_{worker_type}_{worker_id}.out  â”‚
                        â”‚     Examples:                                   â”‚
                        â”‚     - worker-3_decode_w0.out                   â”‚
                        â”‚     - eos0219_prefill_w1.out                   â”‚
                        â”‚                                                 â”‚
                        â”‚  Content:                                       â”‚
                        â”‚  â€¢ Batch metrics lines                         â”‚
                        â”‚  â€¢ Memory snapshot lines                       â”‚
                        â”‚  â€¢ TP/DP/EP configuration                      â”‚
                        â”‚  â€¢ Launch command                              â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â”‚ detect backend type
                                         â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   NodeAnalyzer                  â”‚
                        â”‚   _detect_backend_type()        â”‚
                        â”‚   â€¢ Checks config.yaml          â”‚
                        â”‚   â€¢ Checks log patterns         â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â”‚ get_node_parser()
                                         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              NodeParser (SGLang or TRT-LLM)            â”‚
        â”‚                                                        â”‚
        â”‚  parse_single_log() - parses one worker's log file    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â”‚ creates
                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            NodeMetadata                                    â”‚
â”‚  Fields:                               Source:                             â”‚
â”‚  â€¢ node_name                           ğŸ“ *_{type}_{id}.out (filename)     â”‚
â”‚  â€¢ worker_type (prefill/decode/agg)    ğŸ“ *_{type}_{id}.out (filename)     â”‚
â”‚  â€¢ worker_id (w0, w1, ...)             ğŸ“ *_{type}_{id}.out (filename)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            BatchMetrics                                    â”‚
â”‚  Fields:                               Source:                             â”‚
â”‚  â€¢ timestamp                           ğŸ“ *.out log lines                  â”‚
â”‚  â€¢ dp, tp, ep                          ğŸ“ *.out log lines                  â”‚
â”‚  â€¢ batch_type (prefill/decode)         ğŸ“ *.out log lines                  â”‚
â”‚  â€¢ new_seq, new_token, cached_token    ğŸ“ *.out log lines                  â”‚
â”‚  â€¢ token_usage                         ğŸ“ *.out log lines                  â”‚
â”‚  â€¢ running_req, queue_req              ğŸ“ *.out log lines                  â”‚
â”‚  â€¢ num_tokens                          ğŸ“ *.out log lines                  â”‚
â”‚  â€¢ input_throughput, gen_throughput    ğŸ“ *.out log lines                  â”‚
â”‚                                                                            â”‚
â”‚  Example log line (SGLang):                                               â”‚
â”‚  2024-12-30 08:10:15 DP0.TP0.EP0 [BATCH] prefill #new-seq: 2 ...         â”‚
â”‚                                                                            â”‚
â”‚  Example log line (TRT-LLM):                                              â”‚
â”‚  [TensorRT-LLM][INFO] [ITERATION] tokens=1024 new_tokens=128 ...         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            MemoryMetrics                                   â”‚
â”‚  Fields:                               Source:                             â”‚
â”‚  â€¢ timestamp                           ğŸ“ *.out log lines                  â”‚
â”‚  â€¢ dp, tp, ep                          ğŸ“ *.out log lines                  â”‚
â”‚  â€¢ avail_mem_gb                        ğŸ“ *.out log lines                  â”‚
â”‚  â€¢ mem_usage_gb                        ğŸ“ *.out log lines                  â”‚
â”‚  â€¢ kv_cache_gb                         ğŸ“ *.out log lines                  â”‚
â”‚  â€¢ kv_tokens                           ğŸ“ *.out log lines                  â”‚
â”‚                                                                            â”‚
â”‚  Example log line (SGLang):                                               â”‚
â”‚  2024-12-30 08:10:15 DP0.TP0.EP0 #running-req: 10, avail_mem=45.2GB      â”‚
â”‚                                                                            â”‚
â”‚  Example log line (TRT-LLM):                                              â”‚
â”‚  [TensorRT-LLM][INFO] Memory Stats: free=48.5GB, kv_cache=12.3GB         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            NodeMetrics                                     â”‚
â”‚  Fields:                               Source:                             â”‚
â”‚  â€¢ metadata: NodeMetadata              (see above)                         â”‚
â”‚  â€¢ batches: list[BatchMetrics]         ğŸ“ *.out log lines                  â”‚
â”‚  â€¢ memory_snapshots: list[MemoryMetrics] ğŸ“ *.out log lines                â”‚
â”‚  â€¢ config: dict                        ğŸ“ *.out log lines                  â”‚
â”‚    - tp_size, dp_size, ep_size         (parsed from DP0.TP2.EP1 tags)     â”‚
â”‚  â€¢ run_id                              (from metadata)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. Node Configuration Flow

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚          Source Files (per node)                â”‚
                        â”‚                                                 â”‚
                        â”‚  ğŸ“ logs/*_{type}_{id}.out - launch command    â”‚
                        â”‚  ğŸ“ logs/*_config.json - node config           â”‚
                        â”‚  ğŸ“ logs/config.yaml - environment vars        â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â”‚ parsed by
                                         â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   NodeAnalyzer                  â”‚
                        â”‚   _populate_config_from_files() â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â”‚ creates
                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      NodeLaunchCommand                                     â”‚
â”‚  Fields:                               Source:                             â”‚
â”‚  â€¢ backend_type (sglang/trtllm)        ğŸ“ *_{type}_{id}.out               â”‚
â”‚  â€¢ worker_type (prefill/decode)        ğŸ“ *_{type}_{id}.out               â”‚
â”‚  â€¢ raw_command                         ğŸ“ *_{type}_{id}.out               â”‚
â”‚  â€¢ extra_args: dict                    ğŸ“ *_{type}_{id}.out               â”‚
â”‚    - model_path, served_model_name,                                        â”‚
â”‚      disaggregation_mode, tp_size,                                         â”‚
â”‚      pp_size, max_num_seqs, ...                                            â”‚
â”‚                                                                            â”‚
â”‚  Example (TRT-LLM):                                                        â”‚
â”‚  python3 -m dynamo.trtllm --model-path /model --disaggregation-mode       â”‚
â”‚    decode --extra-engine-args /logs/trtllm_config_decode.yaml             â”‚
â”‚                                                                            â”‚
â”‚  Example (SGLang):                                                         â”‚
â”‚  python -m sglang.launch_server --model-path /model --disagg-mode prefill â”‚
â”‚    --tp-size 2 --dp-size 1                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          NodeConfig (TypedDict)                            â”‚
â”‚  Fields:                               Source:                             â”‚
â”‚  â€¢ launch_command: NodeLaunchCommand   ğŸ“ *_{type}_{id}.out               â”‚
â”‚  â€¢ environment: dict[str, str]         ğŸ“ config.yaml                     â”‚
â”‚    - NCCL settings, CUDA settings,                                         â”‚
â”‚      model paths, etc.                                                     â”‚
â”‚  â€¢ gpu_info: dict (optional)           ğŸ“ *_config.json                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            NodeInfo                                        â”‚
â”‚  Top-level container combining metrics and configuration                  â”‚
â”‚                                                                            â”‚
â”‚  Fields:                                                                   â”‚
â”‚  â€¢ metrics: NodeMetrics                (performance data)                  â”‚
â”‚  â€¢ node_config: NodeConfig             (configuration)                    â”‚
â”‚                                                                            â”‚
â”‚  Convenience properties delegate to nested fields:                         â”‚
â”‚  â€¢ node_name â†’ metrics.metadata.node_name                                 â”‚
â”‚  â€¢ worker_type â†’ metrics.metadata.worker_type                             â”‚
â”‚  â€¢ launch_command â†’ node_config["launch_command"]                         â”‚
â”‚  â€¢ environment â†’ node_config["environment"]                               â”‚
â”‚  â€¢ batches â†’ metrics.batches                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7. Complete Data Model Hierarchy

```
BenchmarkRun (top-level container for entire run)
â”‚
â”œâ”€ metadata: RunMetadata
â”‚  â””â”€ Source: ğŸ“ metadata.json, config.yaml
â”‚
â”œâ”€ profiler_metadata: ProfilerMetadata
â”‚  â””â”€ Source: ğŸ“ logs/benchmark.out
â”‚
â”œâ”€ profiler: ProfilerResults
â”‚  â””â”€ Source: ğŸ“ sa-bench_isl_*_osl_*/result_*.json
â”‚              ğŸ“ logs/artifacts/*/profile_export_aiperf.json
â”‚
â”œâ”€ benchmark_launch_command: BenchmarkLaunchCommand
â”‚  â””â”€ Source: ğŸ“ logs/benchmark.out
â”‚
â””â”€ nodes: list[NodeInfo]
   â””â”€ Each NodeInfo contains:
      â”‚
      â”œâ”€ metrics: NodeMetrics
      â”‚  â”œâ”€ metadata: NodeMetadata
      â”‚  â”‚  â””â”€ Source: ğŸ“ logs/*_{type}_{id}.out (filename)
      â”‚  â”œâ”€ batches: list[BatchMetrics]
      â”‚  â”‚  â””â”€ Source: ğŸ“ logs/*_{type}_{id}.out (log lines)
      â”‚  â”œâ”€ memory_snapshots: list[MemoryMetrics]
      â”‚  â”‚  â””â”€ Source: ğŸ“ logs/*_{type}_{id}.out (log lines)
      â”‚  â””â”€ config: dict
      â”‚     â””â”€ Source: ğŸ“ logs/*_{type}_{id}.out (DP/TP/EP tags)
      â”‚
      â””â”€ node_config: NodeConfig
         â”œâ”€ launch_command: NodeLaunchCommand
         â”‚  â””â”€ Source: ğŸ“ logs/*_{type}_{id}.out (command line)
         â”œâ”€ environment: dict[str, str]
         â”‚  â””â”€ Source: ğŸ“ logs/config.yaml
         â””â”€ gpu_info: dict (optional)
            â””â”€ Source: ğŸ“ logs/*_config.json
```

---

## 8. Parser Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Parser Registry System                            â”‚
â”‚                                                                          â”‚
â”‚  Decorators:                                                            â”‚
â”‚  â€¢ @register_benchmark_parser("sa-bench")                               â”‚
â”‚  â€¢ @register_benchmark_parser("mooncake-router")                        â”‚
â”‚  â€¢ @register_node_parser("sglang")                                      â”‚
â”‚  â€¢ @register_node_parser("trtllm")                                      â”‚
â”‚                                                                          â”‚
â”‚  Lookup Functions:                                                      â”‚
â”‚  â€¢ get_benchmark_parser(type) â†’ BenchmarkParser                         â”‚
â”‚  â€¢ get_node_parser(type) â†’ NodeParser                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                â”‚
                    â–¼                                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  BenchmarkParsers    â”‚       â”‚    NodeParsers       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                       â–¼        â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SABench     â”‚    â”‚  Mooncake    â”‚  â”‚ SGLang  â”‚   â”‚   TRT-LLM    â”‚
â”‚   Parser     â”‚    â”‚   Parser     â”‚  â”‚ Parser  â”‚   â”‚   Parser     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Each parser implements:
  Benchmark:
    â€¢ find_result_directory() - locate result files
    â€¢ parse_result_directory() - parse all results
    â€¢ parse_result_json() - parse single result file
    â€¢ parse_launch_command() - extract command

  Node:
    â€¢ parse_logs() - parse directory of logs
    â€¢ parse_single_log() - parse one worker log
    â€¢ parse_launch_command() - extract command
```

---

## 9. Parsing Strategy: JSON-First Approach

### Design Principle: JSON as Source of Truth âœ¨

The parser infrastructure follows a **JSON-first** approach for benchmark results:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Benchmark Result Parsing Priority                     â”‚
â”‚                                                                          â”‚
â”‚  1ï¸âƒ£ PRIMARY: JSON Result Files (Source of Truth)                        â”‚
â”‚     ğŸ“ result_*.json (SA-Bench)                                         â”‚
â”‚     ğŸ“ profile_export_aiperf.json (Mooncake-Router)                     â”‚
â”‚     - Complete, structured data                                         â”‚
â”‚     - Machine-readable, validated format                                â”‚
â”‚     - Contains all metrics with precision                               â”‚
â”‚                                                                          â”‚
â”‚  2ï¸âƒ£ FALLBACK: benchmark.out Parsing                                     â”‚
â”‚     ğŸ“ logs/benchmark.out                                               â”‚
â”‚     - Used ONLY when JSON files are unavailable                         â”‚
â”‚     - Regex-based extraction from human-readable logs                   â”‚
â”‚     - May be incomplete or imprecise                                    â”‚
â”‚     - Logged as fallback in parser output                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementation

All benchmark parsers implement this strategy in `parse_result_directory()`:

```python
def parse_result_directory(self, result_dir: Path) -> list[dict[str, Any]]:
    results = []
    
    # 1ï¸âƒ£ PRIMARY: Try JSON files first
    for json_file in result_dir.glob("*.json"):  # or rglob() for nested
        result = self.parse_result_json(json_file)
        if result.get("output_tps"):
            results.append(result)
            logger.info(f"Loaded from JSON: {json_file}")
    
    # 2ï¸âƒ£ FALLBACK: If no JSON found, try benchmark.out
    if not results:
        benchmark_out = result_dir / "benchmark.out"
        if benchmark_out.exists():
            logger.info("No JSON results found, falling back to .out parsing")
            fallback_result = self.parse(benchmark_out)
            if fallback_result.get("output_tps"):
                results.append(fallback_result)
        else:
            logger.warning(f"No results found in {result_dir}")
    
    return results
```

### Rationale

1. **Accuracy**: JSON files contain exact, validated data
2. **Completeness**: JSON includes all metrics, not just what's in logs
3. **Reliability**: Structured format vs regex parsing
4. **Performance**: JSON parsing is faster than regex on large logs
5. **Maintainability**: Less brittle than log format changes

### When Fallback is Used

The fallback to `.out` file parsing occurs when:
- JSON result files are missing (incomplete benchmark run)
- Results directory doesn't contain expected JSON files
- Legacy runs from before JSON export was implemented

---

## 10. Caching Layer

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           CacheManager                                   â”‚
â”‚                                                                          â”‚
â”‚  Caches to ğŸ“ {run_path}/cached_assets/                                 â”‚
â”‚                                                                          â”‚
â”‚  Cached Data:                                                           â”‚
â”‚  â€¢ benchmark_results.parquet - ProfilerResults                          â”‚
â”‚  â€¢ node_metrics.parquet - NodeMetrics (all workers)                     â”‚
â”‚  â€¢ cache_metadata.json - timestamps, source patterns                    â”‚
â”‚                                                                          â”‚
â”‚  Cache Validation:                                                      â”‚
â”‚  â€¢ Checks if source files have changed (mtime)                          â”‚
â”‚  â€¢ Invalidates cache if patterns don't match                            â”‚
â”‚  â€¢ Automatically rebuilds if invalid                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Flow with cache:
  1. RunLoader checks cache validity
  2. If valid â†’ deserialize from .parquet
  3. If invalid â†’ parse from source files â†’ cache results
  4. Populate NodeConfig from files (not cached)
```

---

## 11. File Structure Summary

```
{run_directory}/
â”œâ”€â”€ metadata.json              â†’ RunMetadata
â”œâ”€â”€ config.yaml                â†’ ProfilerMetadata.isl/osl
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ benchmark.out          â†’ BenchmarkLaunchCommand, ProfilerMetadata, (fallback metrics)
â”‚   â”œâ”€â”€ config.yaml            â†’ NodeConfig.environment
â”‚   â”œâ”€â”€ {node}_{type}_{id}.out â†’ NodeMetrics, NodeLaunchCommand
â”‚   â”œâ”€â”€ {node}_config.json     â†’ NodeConfig.gpu_info
â”‚   â””â”€â”€ sa-bench_isl_*/
â”‚       â””â”€â”€ result_*.json      â†’ ProfilerResults (PRIMARY âœ¨)
â”‚   â””â”€â”€ artifacts/
â”‚       â””â”€â”€ */
â”‚           â””â”€â”€ profile_export_aiperf.json â†’ ProfilerResults (PRIMARY âœ¨)
â””â”€â”€ cached_assets/
    â”œâ”€â”€ benchmark_results.parquet
    â”œâ”€â”€ node_metrics.parquet
    â””â”€â”€ cache_metadata.json
```

**Note**: JSON files are the primary source of truth for benchmark results.
The `.out` files serve as fallback for legacy/incomplete runs.

---

## 12. Key Design Principles

1. **Parser Autonomy**: Each parser knows how to find and parse its own files
   - `find_result_directory()` encapsulates file discovery logic
   - RunLoader doesn't need benchmark-specific knowledge

2. **JSON-First Parsing** âœ¨: JSON files are the primary source of truth
   - `parse_result_json()` for structured, accurate data
   - `parse()` method is fallback for when JSON is unavailable
   - Logged clearly when fallback is used

3. **Separation of Concerns**:
   - **Metrics** (NodeMetrics): Performance data from log parsing
   - **Configuration** (NodeConfig): Launch commands, environment, GPU info
   - **Metadata** (NodeMetadata): Worker identification

4. **Caching Strategy**:
   - Cache expensive parsing operations (batch/memory metrics)
   - Don't cache configuration (files are small, may change)
   - Validate cache against source file timestamps

5. **Extensibility**:
   - New benchmark types: Implement BenchmarkParserProtocol
   - New node backends: Implement NodeParserProtocol
   - Register with decorator â†’ automatically available

6. **Data Flow Direction**:
   ```
   JSON Files (Primary) â”€â”€â”
                          â”œâ”€â”€â–º Parsers â”€â”€â–º Data Models â”€â”€â–º Cache â”€â”€â–º Application
   .out Files (Fallback) â”€â”˜
   ```

---

## 12. Usage Example

```python
from pathlib import Path
from analysis.srtlog.run_loader import RunLoader

# Load a run
loader = RunLoader("/path/to/runs")
run = loader.load_single("553")

# Access metadata (from metadata.json)
print(f"Job: {run.metadata.job_id}")
print(f"Model: {run.metadata.model.path}")

# Access profiler results (from result_*.json or profile_export_aiperf.json)
print(f"Output TPS: {run.profiler.output_tps}")
print(f"Mean TTFT: {run.profiler.mean_ttft_ms}")

# Access benchmark launch command (from logs/benchmark.out)
print(f"Benchmark: {run.benchmark_launch_command.benchmark_type}")
print(f"Arguments: {run.benchmark_launch_command.extra_args}")

# Load node metrics (from logs/*_{type}_{id}.out)
nodes = loader.load_node_metrics_for_run(run)
for node in nodes:
    # Metrics from log file parsing
    print(f"Node: {node.node_name} ({node.worker_type})")
    print(f"  Batches: {len(node.batches)}")
    print(f"  Memory snapshots: {len(node.memory_snapshots)}")
    
    # Config from config files
    print(f"  Backend: {node.launch_command.backend_type}")
    print(f"  Environment vars: {len(node.environment)}")
```

