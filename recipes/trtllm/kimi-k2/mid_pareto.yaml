name: "ctx4_gen1_dep32_batch8_eplb0_mtp3"

model:
  path: "kimi-k2"
  container: "nvcr.io#nvidia/ai-dynamo/tensorrtllm-runtime:0.8.1.post3"
  precision: "fp4"

resources:
  gpu_type: "gb200"
  prefill_nodes: 4
  prefill_workers: 4
  gpus_per_prefill: 4

  decode_workers: 1
  decode_nodes: 8
  gpus_per_decode: 32

  gpus_per_node: 4

backend:
  type: trtllm

  prefill_environment:
    NCCL_GRAPH_MIXING_SUPPORT: "0"
    OMPI_MCA_coll_ucc_enable: "0"
    TLLM_LOG_LEVEL: "INFO"
    TRTLLM_ENABLE_PDL: "1"
    TRTLLM_SERVER_DISABLE_GC: "1"
    TRTLLM_WORKER_DISABLE_GC: "1"


  decode_environment:
    NCCL_GRAPH_MIXING_SUPPORT: "0"
    OMPI_MCA_coll_ucc_enable: "0"
    TLLM_LOG_LEVEL: "INFO"
    TRTLLM_SERVER_DISABLE_GC: "1"
    TRTLLM_WORKER_DISABLE_GC: "1"

  trtllm_config:
    prefill:
      max_batch_size: 2
      max_num_tokens: 16896
      max_seq_len: 8232
      tensor_parallel_size: 4
      moe_expert_parallel_size: 4
      enable_attention_dp: true
      pipeline_parallel_size: 1
      print_iter_log: true
      cuda_graph_config: null
      disable_overlap_scheduler: true
      moe_config:
        backend: TRTLLM
      kv_cache_config:
        enable_block_reuse: false
        free_gpu_memory_fraction: 0.75
        dtype: fp8
      cache_transceiver_config:
        max_tokens_in_buffer: 8448
        backend: UCX
      trust_remote_code: true
      speculative_config:
        decoding_type: Eagle
        max_draft_len: 3
        eagle3_one_model: 'true'
        speculative_model_dir: /model/eagle

    decode:
      tensor_parallel_size: 32
      moe_expert_parallel_size: 32
      enable_attention_dp: true
      enable_lm_head_tp_in_adp: true
      pipeline_parallel_size: 1
      max_batch_size: 8
      max_num_tokens: 32
      max_seq_len: 9256
      cuda_graph_config:
        enable_padding: true
        batch_sizes:
        - 1
        - 2
        - 4
        - 8
        - 16
        - 32
        - 64
        - 128
        - 256
        - 512
        - 768
        - 1024
        - 2048
        - 8
      print_iter_log: true
      kv_cache_config:
        enable_block_reuse: false
        free_gpu_memory_fraction: 0.7
        dtype: fp8
      moe_config:
        backend: WIDEEP
        use_low_precision_moe_combine: true
      cache_transceiver_config:
        max_tokens_in_buffer: 8448
        backend: UCX
      stream_interval: 100
      num_postprocess_workers: 4
      trust_remote_code: true
      speculative_config:
        decoding_type: Eagle
        max_draft_len: 3
        eagle3_one_model: 'true'
        speculative_model_dir: /model/eagle

benchmark:
  type: "sa-bench"
  isl: 8192
  osl: 1024
  concurrencies: "256"
  req_rate: "inf"

frontend:
  type: "dynamo"
  enable_multiple_frontends: false

dynamo:
  install: false
